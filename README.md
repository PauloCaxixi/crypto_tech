# ğŸ“Š Crypto Forecasting Pipeline

Sistema completo de **coleta, processamento, previsÃ£o e visualizaÃ§Ã£o de preÃ§os de criptomoedas** utilizando **Machine Learning**.
O projeto integra **ETL (Extract, Transform, Load)**, **Modelos de PrevisÃ£o (Random Forest)**, **API REST (FastAPI)** e **Dashboard em tempo real (Streamlit)**.

---

## ğŸ—ï¸ Arquitetura do Projeto

```mermaid
flowchart TD
    A[extract.py<br>ğŸ“¡ Coleta API CoinGecko] --> B[crypto.db<br>ğŸ’¾ SQLite]
    B --> C[transform.py<br>âš™ï¸ GeraÃ§Ã£o de Features]
    C --> D[train.py<br>ğŸ§  Treinamento Random Forest]
    D --> E[predict.py<br>ğŸ”® PrevisÃµes Futuras]
    E --> F1[api/main.py<br>ğŸŒ FastAPI]
    E --> F2[dashboard/app.py<br>ğŸ“Š Streamlit]
```

* **ETL contÃ­nuo**: coleta de dados e geraÃ§Ã£o de features.
* **Treinamento periÃ³dico**: re-treino automÃ¡tico a cada ciclo.
* **PrevisÃµes em tempo real**: atualizaÃ§Ã£o a cada 30 segundos.
* **Consumo de dados**: via **API REST** ou **Dashboard interativo**.

---

## ğŸ“‚ Estrutura de Pastas

```
.
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py      # Coleta preÃ§os da API CoinGecko â†’ SQLite
â”‚   â”œâ”€â”€ transform.py    # Gera features e salva em Parquet
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ train.py        # Treina modelos Random Forest
â”‚   â”œâ”€â”€ predict.py      # Gera previsÃµes e salva no log
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py         # API REST com FastAPI
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py          # Dashboard Streamlit
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ crypto.db       # Banco SQLite
â”‚   â””â”€â”€ processed/      # Features & previsÃµes (Parquet)
â”œâ”€â”€ models/             # Modelos treinados (joblib)
â”œâ”€â”€ run_all.py          # Orquestrador de processos
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ InstalaÃ§Ã£o

### ğŸ”¹ 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/crypto-pipeline.git
cd crypto-pipeline
```

### ğŸ”¹ 2. Crie o ambiente virtual

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

### ğŸ”¹ 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ ExecuÃ§Ã£o

### ğŸ”¹ Rodar todo o sistema

```bash
python run_all.py
```

Esse script orquestra 4 processos independentes:

1. **Coletor contÃ­nuo** â†’ `etl/extract.py`
2. **Pipeline periÃ³dico (30s)** â†’ `etl/transform.py â†’ model/train.py â†’ model/predict.py`
3. **API FastAPI** â†’ disponÃ­vel em `http://127.0.0.1:8000/docs`
4. **Dashboard Streamlit** â†’ disponÃ­vel em `http://127.0.0.1:8501`

O navegador serÃ¡ aberto automaticamente com **API + Dashboard**.

---

## ğŸŒ API Endpoints

* **Status** â†’ `GET /status`
* **Listar moedas** â†’ `GET /moedas`
* **Prever moeda** â†’ `GET /prever/{moeda}`
* **HistÃ³rico de previsÃµes** â†’ `GET /previsoes/{moeda}`

ğŸ“Œ DocumentaÃ§Ã£o interativa:

* Swagger UI â†’ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
* Redoc â†’ [http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)

---

## ğŸ“Š Dashboard

O dashboard em **Streamlit** oferece:

âœ… HistÃ³rico de preÃ§os em tempo real
âœ… GrÃ¡ficos de previsÃ£o para a prÃ³xima hora
âœ… MÃ©tricas de acurÃ¡cia
âœ… Comparativo entre moedas
âœ… ExportaÃ§Ã£o de dados para CSV

Acesse em: [http://127.0.0.1:8501](http://127.0.0.1:8501)

---

## âš¡ Tecnologias Utilizadas

* **Python 3.10+**
* **FastAPI** (API REST)
* **Streamlit + Plotly** (Dashboard interativo)
* **Scikit-learn** (Machine Learning)
* **SQLite** (Banco local)
* **Pandas / NumPy** (ManipulaÃ§Ã£o de dados)

---

## ğŸ“ˆ Fluxo de AtualizaÃ§Ã£o em Tempo Real

* **A cada 30s** o pipeline roda:

  1. Extrai novos preÃ§os
  2. Atualiza features
  3. Re-treina os modelos
  4. Gera previsÃµes
* Dashboard e API **refletem automaticamente os dados mais recentes**.

---

## ğŸ› ï¸ DiagnÃ³stico

O Dashboard possui seÃ§Ã£o de diagnÃ³stico que mostra:

* Ãšltima atualizaÃ§Ã£o dos arquivos
* Quantidade de registros carregados
* Status do log de previsÃµes

